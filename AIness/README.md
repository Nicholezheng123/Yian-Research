# AI-ness Metric

## Overview
This project develops an **AI-ness metric** to quantify how conceptually close a research paper is to artificial intelligence. Using embedding-based similarity measures, the analysis evaluates how AI-related research varies across fields, time, and author behavior.

## Research Goal
As AI methods spread beyond traditional AI fields, it is increasingly difficult to understand **where and how AI is influencing research**. This project aims to evaluate patterns in AI adoption by analyzing AI-ness trends across research fields, publication years, and authors.

## What I Did
- Analyzed AI-ness scores derived from **L2 distance** and **cosine similarity**
- Compared AI influence across research fields
- Studied temporal trends in AI-ness over time
- Examined whether AI tool usage correlates with AI-ness
- Evaluated differences in AI-ness with and without abstracts

## Key Takeaway
AI-ness reflects **conceptual proximity to AI**, not just explicit AI tool usage. Fields vary widely in how and when they adopt AI methods, and similarity metrics capture these differences at scale.

## Learn More
For full methodology, visualizations, and detailed results, see the project slides:  
ðŸ‘‰ **[AI-ness Metric â€“ Full Analysis Slides](https://docs.google.com/presentation/d/1PMICvjU_r5kbPQXO0NCNKpF4-rXvYNFZgraLIA-TxhI/edit?usp=sharing)**

## Author
**Nichole Zheng**
