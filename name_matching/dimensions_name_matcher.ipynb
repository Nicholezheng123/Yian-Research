{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ed80129",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>ORCID_list</th>\n",
       "      <th>Institution</th>\n",
       "      <th>Institution_df2</th>\n",
       "      <th>Year_Start</th>\n",
       "      <th>Year_End</th>\n",
       "      <th>Doctorate Completion Date</th>\n",
       "      <th>Doctorate Granting Institution</th>\n",
       "      <th>Cohort_Group</th>\n",
       "      <th>Cohort_Group_df2</th>\n",
       "      <th>Cohort_Type</th>\n",
       "      <th>Alumni</th>\n",
       "      <th>Google Scholars</th>\n",
       "      <th>LinkedIn</th>\n",
       "      <th>Additional Professional Profiles (from Surveys)</th>\n",
       "      <th>LinkedIn (from Surveys)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adam  Roy</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"University of California, San Diego\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Cohort</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adam Fouda</td>\n",
       "      <td>['https://orcid.org/0000-0002-9445-5537']</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>The University of Chicago</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>2026</td>\n",
       "      <td>4/5/20</td>\n",
       "      <td>University of Nottingham,</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Cohort</td>\n",
       "      <td>NaN</td>\n",
       "      <td>scholar.google.com/citations?view_op=view_cita...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aditya Nandy</td>\n",
       "      <td>['https://orcid.org/0000-0001-7137-5449']</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>The University of Chicago</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>2025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Massachusetts Institute of Technology,</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Cohort</td>\n",
       "      <td>checked</td>\n",
       "      <td>scholar.google.com/citations?user=gbTUmC8AAAAJ...</td>\n",
       "      <td>www.linkedin.com/in/adityanandy/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aidan Crilly</td>\n",
       "      <td>['https://orcid.org/0000-0002-0429-9332']</td>\n",
       "      <td>Imperial</td>\n",
       "      <td>Imperial College London</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>2025</td>\n",
       "      <td>6/1/20</td>\n",
       "      <td>Imperial College London,</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Cohort</td>\n",
       "      <td>NaN</td>\n",
       "      <td>scholar.google.co.uk/citations?user=ILkvB-EAAA...</td>\n",
       "      <td>www.linkedin.com/in/aidan-crilly-22572ba0/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Akshay Ajagekar</td>\n",
       "      <td>['https://orcid.org/0000-0001-9493-6050']</td>\n",
       "      <td>Cornell</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>2025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>scholar.google.com/citations?user=JCRfLuIAAAAJ</td>\n",
       "      <td>www.linkedin.com/in/akshayajagekar</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Name                                 ORCID_list Institution  \\\n",
       "0        Adam  Roy                                         []         NaN   \n",
       "1       Adam Fouda  ['https://orcid.org/0000-0002-9445-5537']     Chicago   \n",
       "2     Aditya Nandy  ['https://orcid.org/0000-0001-7137-5449']     Chicago   \n",
       "3     Aidan Crilly  ['https://orcid.org/0000-0002-0429-9332']    Imperial   \n",
       "4  Akshay Ajagekar  ['https://orcid.org/0000-0001-9493-6050']     Cornell   \n",
       "\n",
       "                         Institution_df2  Year_Start Year_End  \\\n",
       "0  \"University of California, San Diego\"         NaN      NaN   \n",
       "1              The University of Chicago      2023.0     2026   \n",
       "2              The University of Chicago      2023.0     2025   \n",
       "3                Imperial College London      2023.0     2025   \n",
       "4                                    NaN      2024.0     2025   \n",
       "\n",
       "  Doctorate Completion Date           Doctorate Granting Institution  \\\n",
       "0                       NaN                                      NaN   \n",
       "1                    4/5/20               University of Nottingham,    \n",
       "2                       NaN  Massachusetts Institute of Technology,    \n",
       "3                    6/1/20                Imperial College London,    \n",
       "4                       NaN                                      NaN   \n",
       "\n",
       "   Cohort_Group  Cohort_Group_df2 Cohort_Type   Alumni  \\\n",
       "0           NaN               4.0      Cohort      NaN   \n",
       "1           2.0               2.0      Cohort      NaN   \n",
       "2           2.0               2.0      Cohort  checked   \n",
       "3           1.0               1.0      Cohort      NaN   \n",
       "4           3.0               NaN         NaN      NaN   \n",
       "\n",
       "                                     Google Scholars  \\\n",
       "0                                                NaN   \n",
       "1  scholar.google.com/citations?view_op=view_cita...   \n",
       "2  scholar.google.com/citations?user=gbTUmC8AAAAJ...   \n",
       "3  scholar.google.co.uk/citations?user=ILkvB-EAAA...   \n",
       "4     scholar.google.com/citations?user=JCRfLuIAAAAJ   \n",
       "\n",
       "                                     LinkedIn  \\\n",
       "0                                         NaN   \n",
       "1                                         NaN   \n",
       "2            www.linkedin.com/in/adityanandy/   \n",
       "3  www.linkedin.com/in/aidan-crilly-22572ba0/   \n",
       "4          www.linkedin.com/in/akshayajagekar   \n",
       "\n",
       "  Additional Professional Profiles (from Surveys) LinkedIn (from Surveys)  \n",
       "0                                             NaN                     NaN  \n",
       "1                                             NaN                     NaN  \n",
       "2                                             NaN                     NaN  \n",
       "3                                             NaN                     NaN  \n",
       "4                                             NaN                     NaN  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nameparser import HumanName\n",
    "from unidecode import unidecode\n",
    "from rapidfuzz import fuzz, process\n",
    "\n",
    "# 1. Load data\n",
    "df = pd.read_csv(\"/share/yin/schmidt/intermediate/20251017_combined_grid_and_metascience_fixed.csv\")\n",
    "df.head()\n",
    "#df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8ffe376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Match CSV created successfully at:\n",
      "/share/yin/nz268/name_matching/name_matching_results.csv\n",
      "              Name Institution Best_Matched_Name  \\\n",
      "0        Adam  Roy         NaN          Adam Roy   \n",
      "1       Adam Fouda     Chicago        Adam Fouda   \n",
      "2     Aditya Nandy     Chicago      Aditya Nandy   \n",
      "3     Aidan Crilly    Imperial      Aidan Crilly   \n",
      "4  Akshay Ajagekar     Cornell   Akshay Ajagekar   \n",
      "\n",
      "                Best_Matched_Institution  Match_Score              Notes  \n",
      "0  \"University of California, San Diego\"        80.00  Medium confidence  \n",
      "1              The University of Chicago        88.75  Medium confidence  \n",
      "2              The University of Chicago        88.75  Medium confidence  \n",
      "3                Imperial College London        90.32    High confidence  \n",
      "4                                               80.00  Medium confidence  \n"
     ]
    }
   ],
   "source": [
    "input_path = \"/share/yin/schmidt/intermediate/20251017_combined_grid_and_metascience_fixed.csv\"\n",
    "output_path = \"/share/yin/nz268/name_matching/name_matching_results.csv\"\n",
    "\n",
    "df = pd.read_csv(input_path)\n",
    "\n",
    "# === 2. Normalize and parse names ===\n",
    "def clean_name(name):\n",
    "    if pd.isna(name):\n",
    "        return \"\"\n",
    "    name = unidecode(str(name)).lower().strip()\n",
    "    parsed = HumanName(name)\n",
    "    return {\n",
    "        \"first\": parsed.first.strip(),\n",
    "        \"middle\": parsed.middle.strip(),\n",
    "        \"last\": parsed.last.strip(),\n",
    "        \"full\": f\"{parsed.first} {parsed.last}\".strip()\n",
    "    }\n",
    "\n",
    "df[\"Name_parsed\"] = df[\"Name\"].apply(clean_name)\n",
    "\n",
    "nickname_map = {\n",
    "    \"bob\": \"robert\", \"rob\": \"robert\", \"liz\": \"elizabeth\",\n",
    "    \"bill\": \"william\", \"katie\": \"katherine\", \"ajay\": \"ajai\",\n",
    "    \"vijay\": \"vijai\"\n",
    "}\n",
    "\n",
    "def replace_nicknames(name_dict):\n",
    "    first = name_dict[\"first\"]\n",
    "    if first in nickname_map:\n",
    "        name_dict[\"first\"] = nickname_map[first]\n",
    "    name_dict[\"full\"] = f\"{name_dict['first']} {name_dict['last']}\".strip()\n",
    "    return name_dict\n",
    "\n",
    "df[\"Name_parsed\"] = df[\"Name_parsed\"].apply(replace_nicknames)\n",
    "\n",
    "# === 3. Similarity functions ===\n",
    "def name_similarity(name1, name2):\n",
    "    if not name1 or not name2:\n",
    "        return 0\n",
    "    score_first = fuzz.token_sort_ratio(name1[\"first\"], name2[\"first\"])\n",
    "    score_last = fuzz.token_sort_ratio(name1[\"last\"], name2[\"last\"])\n",
    "    score_full = fuzz.token_sort_ratio(name1[\"full\"], name2[\"full\"])\n",
    "    return 0.5 * score_last + 0.3 * score_first + 0.2 * score_full\n",
    "\n",
    "def institution_similarity(inst1, inst2):\n",
    "    if pd.isna(inst1) or pd.isna(inst2):\n",
    "        return 0\n",
    "    return fuzz.token_sort_ratio(unidecode(str(inst1).lower()), unidecode(str(inst2).lower()))\n",
    "\n",
    "# === 4. Prepare database side ===\n",
    "db_names = df[\"Name_parsed\"].tolist()\n",
    "db_insts = df[\"Institution_df2\"].fillna(\"\").tolist()\n",
    "\n",
    "# === 5. Match loop ===\n",
    "matches = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    fellowship_name = row[\"Name_parsed\"]\n",
    "    fellowship_inst = row.get(\"Institution\", \"\")\n",
    "    \n",
    "    best_match = None\n",
    "    best_score = 0\n",
    "    best_inst = \"\"\n",
    "    \n",
    "    for i, db_name in enumerate(db_names):\n",
    "        score_name = name_similarity(fellowship_name, db_name)\n",
    "        score_inst = institution_similarity(fellowship_inst, db_insts[i])\n",
    "        combined = 0.8 * score_name + 0.2 * score_inst\n",
    "        \n",
    "        if combined > best_score:\n",
    "            best_score = combined\n",
    "            best_match = db_name\n",
    "            best_inst = db_insts[i]\n",
    "    \n",
    "    # Label confidence\n",
    "    if best_score >= 90:\n",
    "        note = \"High confidence\"\n",
    "    elif best_score >= 75:\n",
    "        note = \"Medium confidence\"\n",
    "    else:\n",
    "        note = \"Low confidence\"\n",
    "    \n",
    "    matches.append({\n",
    "        \"Name\": row[\"Name\"],\n",
    "        \"Institution\": fellowship_inst,\n",
    "        \"Best_Matched_Name\": f\"{best_match['first'].title()} {best_match['last'].title()}\",\n",
    "        \"Best_Matched_Institution\": best_inst,\n",
    "        \"Match_Score\": round(best_score, 2),\n",
    "        \"Notes\": note\n",
    "    })\n",
    "\n",
    "# === 6. Save match CSV ===\n",
    "match_df = pd.DataFrame(matches)\n",
    "match_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"✅ Match CSV created successfully at:\\n{output_path}\")\n",
    "print(match_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "19bd7422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset with 277 rows.\n",
      "Nickname map loaded with 2163 entries.\n",
      "\n",
      "✅ Match CSV created successfully at:\n",
      "/share/yin/nz268/name_matching/name_matching_results.csv\n",
      "⚠️  Low-confidence matches saved separately at:\n",
      "/share/yin/nz268/name_matching/name_matching_results_low_confidence.csv\n",
      "\n",
      "Preview:\n",
      "              Name Institution Best_Matched_Name  \\\n",
      "0        Adam  Roy         NaN          Adam Roy   \n",
      "1       Adam Fouda     Chicago        Adam Fouda   \n",
      "2     Aditya Nandy     Chicago      Aditya Nandy   \n",
      "3     Aidan Crilly    Imperial      Aidan Crilly   \n",
      "4  Akshay Ajagekar     Cornell   Akshay Ajagekar   \n",
      "\n",
      "                Best_Matched_Institution  Match_Score              Notes  \n",
      "0  \"University of California, San Diego\"        80.00  Medium confidence  \n",
      "1              The University of Chicago        88.75  Medium confidence  \n",
      "2              The University of Chicago        88.75  Medium confidence  \n",
      "3                Imperial College London        90.32    High confidence  \n",
      "4                                               80.00  Medium confidence  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nameparser import HumanName\n",
    "from unidecode import unidecode\n",
    "from rapidfuzz import fuzz\n",
    "from itertools import product\n",
    "\n",
    "# 1. File paths \n",
    "input_path = \"/share/yin/schmidt/intermediate/20251017_combined_grid_and_metascience_fixed.csv\"\n",
    "nicknames_path = \"/share/yin/bing/schmidt_sciences/stage_1/names.csv\"\n",
    "output_path = \"/share/yin/nz268/name_matching/name_matching_results.csv\"\n",
    "\n",
    "# 2. Load fellowship/database data \n",
    "df = pd.read_csv(input_path)\n",
    "print(f\"Loaded dataset with {len(df)} rows.\")\n",
    "\n",
    "# 3. Normalize and parse names \n",
    "def clean_name(name):\n",
    "    \"\"\"Normalize a name (remove accents, lowercase, parse first/middle/last).\"\"\"\n",
    "    if pd.isna(name):\n",
    "        return {\"first\": \"\", \"middle\": \"\", \"last\": \"\", \"full\": \"\"}\n",
    "    name = unidecode(str(name)).lower().strip()\n",
    "    parsed = HumanName(name)\n",
    "    return {\n",
    "        \"first\": parsed.first.strip(),\n",
    "        \"middle\": parsed.middle.strip(),\n",
    "        \"last\": parsed.last.strip(),\n",
    "        \"full\": f\"{parsed.first} {parsed.last}\".strip()\n",
    "    }\n",
    "\n",
    "df[\"Name_parsed\"] = df[\"Name\"].apply(clean_name)\n",
    "\n",
    "# 4. Load and construct nickname map \n",
    "nicknames_map = pd.read_csv(nicknames_path)\n",
    "\n",
    "# Map name → set of nicknames\n",
    "nicknames_per_name = nicknames_map.groupby(\"name1\")[\"name2\"].agg(set).to_dict()\n",
    "# Map nickname → set of full names\n",
    "names_per_nickname = nicknames_map.groupby(\"name2\")[\"name1\"].agg(set).to_dict()\n",
    "\n",
    "# Merge both directions into one unified dictionary\n",
    "final_nicknames_map = nicknames_per_name.copy()\n",
    "for name in names_per_nickname:\n",
    "    final_nicknames_map[name] = (\n",
    "        final_nicknames_map.get(name, set()).union(names_per_nickname[name])\n",
    "    )\n",
    "\n",
    "print(f\"Nickname map loaded with {len(final_nicknames_map)} entries.\")\n",
    "\n",
    "# 5. Similarity functions\n",
    "def name_similarity_with_nicknames(name1, name2, nickname_map):\n",
    "    \"\"\"Compute fuzzy similarity between two names, accounting for nicknames.\"\"\"\n",
    "    if not name1 or not name2:\n",
    "        return 0\n",
    "\n",
    "    # Generate variant sets for first names\n",
    "    variants1 = {name1[\"first\"]} | nickname_map.get(name1[\"first\"], set())\n",
    "    variants2 = {name2[\"first\"]} | nickname_map.get(name2[\"first\"], set())\n",
    "\n",
    "    # Compare all nickname combinations\n",
    "    best_first_score = max(\n",
    "        fuzz.token_sort_ratio(v1, v2)\n",
    "        for v1, v2 in product(variants1, variants2)\n",
    "    )\n",
    "\n",
    "    # Compare last and full name normally\n",
    "    score_last = fuzz.token_sort_ratio(name1[\"last\"], name2[\"last\"])\n",
    "    score_full = fuzz.token_sort_ratio(name1[\"full\"], name2[\"full\"])\n",
    "\n",
    "    # Weighted score: last name most important\n",
    "    return 0.5 * score_last + 0.3 * best_first_score + 0.2 * score_full\n",
    "\n",
    "\n",
    "def institution_similarity(inst1, inst2):\n",
    "    \"\"\"Compute fuzzy similarity between two institution names.\"\"\"\n",
    "    if pd.isna(inst1) or pd.isna(inst2):\n",
    "        return 0\n",
    "    return fuzz.token_sort_ratio(unidecode(str(inst1).lower()), unidecode(str(inst2).lower()))\n",
    "\n",
    "# 6. Prepare reference lists \n",
    "db_names = df[\"Name_parsed\"].tolist()\n",
    "db_insts = df[\"Institution_df2\"].fillna(\"\").tolist()\n",
    "\n",
    "# 7. Match loop \n",
    "matches = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    fellowship_name = row[\"Name_parsed\"]\n",
    "    fellowship_inst = row.get(\"Institution\", \"\")\n",
    "\n",
    "    best_match = None\n",
    "    best_score = 0\n",
    "    best_inst = \"\"\n",
    "\n",
    "    # Compare with all database names\n",
    "    for i, db_name in enumerate(db_names):\n",
    "        score_name = name_similarity_with_nicknames(fellowship_name, db_name, final_nicknames_map)\n",
    "        score_inst = institution_similarity(fellowship_inst, db_insts[i])\n",
    "        combined = 0.8 * score_name + 0.2 * score_inst\n",
    "\n",
    "        if combined > best_score:\n",
    "            best_score = combined\n",
    "            best_match = db_name\n",
    "            best_inst = db_insts[i]\n",
    "\n",
    "    # Confidence labels\n",
    "    if best_score >= 90:\n",
    "        note = \"High confidence\"\n",
    "    elif best_score >= 75:\n",
    "        note = \"Medium confidence\"\n",
    "    else:\n",
    "        note = \"Low confidence\"\n",
    "\n",
    "    matches.append({\n",
    "        \"Name\": row[\"Name\"],\n",
    "        \"Institution\": fellowship_inst,\n",
    "        \"Best_Matched_Name\": f\"{best_match['first'].title()} {best_match['last'].title()}\",\n",
    "        \"Best_Matched_Institution\": best_inst,\n",
    "        \"Match_Score\": round(best_score, 2),\n",
    "        \"Notes\": note\n",
    "    })\n",
    "\n",
    "# 8. Save results\n",
    "match_df = pd.DataFrame(matches)\n",
    "match_df.to_csv(output_path, index=False)\n",
    "\n",
    "# Save low-confidence matches for manual review\n",
    "low_conf_df = match_df[match_df[\"Notes\"] == \"Low confidence\"]\n",
    "low_conf_path = output_path.replace(\".csv\", \"_low_confidence.csv\")\n",
    "low_conf_df.to_csv(low_conf_path, index=False)\n",
    "\n",
    "print(f\"\\n✅ Match CSV created successfully at:\\n{output_path}\")\n",
    "print(f\"⚠️  Low-confidence matches saved separately at:\\n{low_conf_path}\")\n",
    "print(\"\\nPreview:\")\n",
    "print(match_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0db62c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-confidence matches saved at: /share/yin/nz268/name_matching/name_matching_results_high_confidence.csv\n",
      "Medium-confidence matches saved at: /share/yin/nz268/name_matching/name_matching_results_medium_confidence.csv\n"
     ]
    }
   ],
   "source": [
    "# Save High-confidence matches \n",
    "high_conf_df = match_df[match_df[\"Notes\"] == \"High confidence\"]\n",
    "high_conf_path = output_path.replace(\".csv\", \"_high_confidence.csv\")\n",
    "high_conf_df.to_csv(high_conf_path, index=False)\n",
    "print(f\"High-confidence matches saved at: {high_conf_path}\")\n",
    "\n",
    "# Save Medium-confidence matches \n",
    "medium_conf_df = match_df[match_df[\"Notes\"] == \"Medium confidence\"]\n",
    "medium_conf_path = output_path.replace(\".csv\", \"_medium_confidence.csv\")\n",
    "medium_conf_df.to_csv(medium_conf_path, index=False)\n",
    "print(f\"Medium-confidence matches saved at: {medium_conf_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62181bf",
   "metadata": {},
   "source": [
    "### Match_Score = weighted fuzzy similarity (0–100)\n",
    "\n",
    "Fuzzy similarity (fuzz.token_sort_ratio) compares fellowship and database names.\n",
    "Each component (first, last, full name) gives a score between 0 and 100.\n",
    "\n",
    "1) Name-level weighting:\n",
    "- Name_Score = 0.5 * Last + 0.3 * First + 0.2 * Full\n",
    "    - last name is most important, first name slightly less, full name least.\n",
    "\n",
    "2) Institution adjustment:\n",
    "- Final_Score = 0.8 * Name_Score + 0.2 * Institution_Score\n",
    "    - institution adds minor weight to refine the match.\n",
    "\n",
    "3) Confidence labels:\n",
    "- ≥ 90 → High confidence\n",
    "- 75–89 → Medium confidence\n",
    "- < 75 → Low confidence"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
